Tresor LUKAKU Démarrage ASAP FREE-LANCE Tel :+33766739050 Mail : lukakutresor@gmail.com 10 rue louise Baumel 92500 Rueil Malmaison ARCHITECTE Big Data & Cloud | DATA SCIENCE |DATA ENGENEER ➢ + 8 ans d’expériences environnement Data ➢ Diplômé d’un Master Big Data et Fouille des données ➢ Expérience en mode projet et run sur des écosystèmes big data ➢ Expertise en traitement de la donnée avec les langages Spark /Scala/ Java/Python et R ➢ Maitrise d’Apache Hadoop Apache Hive Apache Kafka Apache Spark et Cloudera ➢ Connaissance en Data Science: Machine Learning DeepLearning ➢ Connaissances et expériences significative autour de de Dataiku PowerBI ➢ Expérience en mode Agile Scrum Technologies maitrisée Compétences principales : MySQL Apache Hadoop MongoDB Apache Kafka Apache Spark Apache Hive Talend Power BI Python Java. Langages de programmation : C++ Java JavaScript PHP Python SQL Scala. Environnement Big Data : Apache Hadoop Apache Hive Apache Kafka Apache Spark Elasticsearch. Cloud computing : Amazon Web Services Google Cloud Platform Microsoft Azure Oracle Talend DataGalaxy. Bases de données : MongoDB MySQL. Data Science & Analyse : Power BI Dataiku DevOps & SysAdmin : Docker MLOPs CI/CD Back and Front-end : Angluar NodJs PHP JavaScript. Gestion de projet : Scrum Jira Langues ➢ Anglais ➢ Français ➢ Université Paris 8 - Master Big Data et Fouille des données ➢ Université Paris 8 - Licence Mathématique et informatique ➢ Lycée Paul Éluard - Préparatoire Concours de Polytechnique; Physique Mathématique ➢ Lycée Suger – Bac à Lauréat Scientifique – Spécialité Mathématique (Mention Bien) Points forts Compétences Diplômes mailto:lukakutresor@gmail.com ➢ Aws (Solution architecture) En cours ➢ Azure ( AZ 900 ) En cours AGIRC-ARRCO Octobre 2022 - En cours ARCHITECTE HADOOP - CLOUDERA Contexte de la mission : Au sein de l'organisation de la Direction Technique Informatique la structure appelée Gouvernance Opérationnelle de l’Edition (GOE) a pour mission d'accompagner le développement logiciel réalisé par les entités fonctionnelles et s’appuie sur 4 entités : Socle Développement Architecture logicielle Centre d’expertise des performances et DBAs&Socles. Les principales missions consistent d'une part à accompagner les équipes dans la conception des modèles de données à administrer les bases et les moteurs de bases de données et à construire les socles SGBD décisionnel et Bigdata. Actions menées : ➢ Architecture technique : • Mise en place des principes directeur sur l’utilisation de cluster cloudera • Vérification de la bonne application des normes et des standards • Proposition d’évolution et de solution pour améliorer l’industrialisation ➢ Administration • Configuration du cluster Cloudera en fonction des besoins identifiés • Suivi des espaces de stockage • Optimisation des chargement des données • Maintien de sécurité ➢ Intégration • Sur de nouveau besoin Etude et proposition de solution Mise en Œuvre de solution validés ➢ Support Technique • Maintien en condition opérationnelle des infrastructures et des composants logiciels du cluster • Assistance auprès des équipes : Optimisation des traitement Prise en main de l’outillage • Chargement des données • Transmission du savoir faire via la rédaction de documentation et transfert de connaissance ➢ Support Décisionnel • Assistance auprès des équipes SI décisionnel dans l’évolution de la plate-forme • Recolte et analyse des besoins • Description et analyse de la plateforme actuelle • Proposition dévolution et élaboration des dossier d’architecture technique et logicielle Environnement technique utilisé: Hadoop Cloudera Shell Spark Hue Hive Python Scala Ansible Certifications MISSIONS EFFECTUEES BOUYGUES TELECOM Février 2022 - Octobre 2022 INGENIEUR BIG DATA Contexte de la mission : Dans le but d'améliorer la compréhension des données de son DataLake et de son DataWarehouse ainsi que de faire croître la culture data au sein de l'entreprise et de faire une étude sur les indicateurs de suivi ""KPI"" / complétudes des données j'ai été sollicité par BOUYGUES TELECOM afin d'apporter mon expertise sur le sujet. Actions menées : ➢ Frise chronologique projet ➢ Démarche modélisation ➢ Documentations des données ➢ Méthodologie des dictionnarisassions des données ➢ Etudes de cas d'usages - Indicateur de suivi KPi et Complétude des donnée Environnement technique utilisé: DataGalaxy(DataCatalog) Scala (sbt) Java Spark MINISTERE DU TOURISME Novembre 2021 – Janvier 2022 DATA INGENIEUR / SCIENTIST Contexte de la mission : Atout France agence de développement touristique de la France est un groupement d'intérêt économique (GIE) de l'état français en matière de tourisme dont les missions ont été définies dans le cadre de la loi tourisme de 2009 pour renforcer les positionnements de la destination France à l'international. Le but de projet était de contribuer activement au marketing international des destinations et filières d'accompagner les territoires dans leur stratégie de développement en favorisant le montage de projets d'investissement afin de stimuler l'offre touristique française en agissant sur la qualité via le pilotage des classements des hébergements touristiques marchands et proposant toute une offre de services en matière de veille/observation et de formation. Atout France met ainsi à disposition de ses 1 300 partenaires publics et privé des outils de compréhension de la demande touristique et leur propose des actions marketing et de promotion autour des marque mondiales de destination afin de renforcer leur développement à l'international. Actions menées : ➢ Agreger des données de sources multiples ➢ Structurer des indicateurs utiles à la décision (politique institutionnels professionnels) ➢ Proposer et de faciliter des analyses partagées et permettre des usages à périmètre pluriel (national régional départementale...) ➢ Automatisations des Pipelines ➢ Création et automatisation de mis à jour des dataframe dans le hubs(Keyrops) ➢ Test Unitaire ➢ Test Integration Environnement technique utilisé: Python Spark Scala(Sbt) PowerBI Minio Agil Jira MISSIONS EFFECTUEES SANOFI Septembre 2020 - Octobre 2021 DATA SCIENTIST Contexte de la mission : Dans l'un de plus grand groupe pharmaceutique mondial ma mission était orientée sur la détection des anomalies la maintenances prédictives des indicateurs de performance (KPIs) et les traitements du langage naturel pour des opérations de qualité́ dans l'industrie manufacturière et au-delà̀ . Actions menées : ➢ Mise en place des algorithmes de classification régression ➢ Mise en place des algorithmes d'apprentissage adaptatif est un modèle basé sur l'IA/ML qui apprend en permanence. ➢ Participer à la définition de nouvelles fonctionnalités de l'outil ➢ Collaborer à la création de la plateforme ➢ Pendre part à la définition des variations récurrentes ➢ Contribuer à l'extension du modèle qui sera mis à disposition et utiliser en production. Environnement technique utilisé: Python AWS R Agile Scrum AVISTO Mars 2020 - Septembre 2020 DATA SCIENTIST Contexte de la mission : Avisto est une entreprise des créations des logiciels informatiques. Dans le cadre de son activité́ils se sont lancés dans les secteurs des jeux de réalité́virtuelle en Ligne PokerIA. Le but de cette mission était de mettre en place un algorithme de Deep Learning(RNN) afin de réaliser un jeu de poker en Ligne pour rivaliser avec les autres poker existant ( google Facebook ). Actions menées : ➢ Études approfondies sur les différents pokers en ligne existant (Etat de l’art) ➢ Écriture du cahier des charges ➢ Conceptions de scenarios et partie graphique du jeux ➢ Mise en place des différentes architectures de Machine learning et du DeepLearning ➢ MLOps Equipe : 1 PO 4 Data Science 2 Développeur Angular Environnement technique utilisé : Python R AWS Spark Angular Agil Scrum SNCF Février 2018 - Février 2020 DATA INGENIEUR / SCIENTIST Contexte de la mission : SNCF Voudriez cartographier les compétences de ses collaborateurs en fonctions de leurs expériences et environnement techniques pour répondre aux besoins de l'entreprises sur différents projets mais également pour cibler les compétences manquantes dans l'entreprise en termes de recrutement Actions menées : ➢ Analyse et développement des applications pour la gestion automatique des appels d'offres ➢ Apprentissage de l'architecture du machine Learning et conceptions des applications mobiles et du site web ➢ Automatisations des Pipelines ➢ Test Unitaire ➢ Test Integration Equipe : 1 PO 8 Data Science 5 Data Engineer Environnement technique utilisé : Python R Java Scala (Sbt) Hadoop Agile PowerBI Dataiku AWS. Laboratoire de recherche Paris Janvier 2015 - Mai 2018 DATA INGENIEUR Contexte de la mission : Dans le cadre des missions en recherche et développement (R&D) j’ai participé dans des différents travaux de l'exploitation de la donnée et les déploiements de l'intelligence artificielle dans divers domaines. Actions menées : ➢ Analyse de sentiment sur le contenu de tweet autour d'un mot-cle ➢ Analyse des réservations de vélo «velib» ➢ Analyse des réservations de vélo «velib» Environnement technique utilisé : Scala Spark Hadoop Cloudera Hive MongoDb MySQL R Knime Kafka PowerBI Dataiku AWS. Concours Challenges sur les synthèses des images et sons ➢ Juin 2015 & Juin 2016 => Langage Java et Python Concours national API8 ➢ Juin 2018 => Langage Java et C Concours national API8 ➢ JUIN 2019 => Langage Java et Python Concours national API8",1446,9480,tresor lukaku démarrage asap freelance tel mail lukakutresorgmailcom rue louise baumel rueil malmaison architecte big data cloud data science data engeneer ➢ ans d’expériences environnement data ➢ diplômé d’un master big data fouille données ➢ expérience mode projet run écosystèmes big data ➢ expertise traitement donnée langages spark scala javapython r ➢ maitrise d’apache hadoop apache hive apache kafka apache spark cloudera ➢ connaissance data science machine learning deeplearning ➢ connaissances expériences significative autour dataiku powerbi ➢ expérience mode agile scrum technologies maitrisée compétences principales mysql apache hadoop mongodb apache kafka apache spark apache hive talend power bi python java langages programmation c java javascript php python sql scala environnement big data apache hadoop apache hive apache kafka apache spark elasticsearch cloud computing amazon web services google cloud platform microsoft azure oracle talend datagalaxy bases données mongodb mysql data science analyse power bi dataiku devops sysadmin docker mlops cicd frontend angluar nodjs php javascript gestion projet scrum jira langues ➢ anglais ➢ français ➢ université paris master big data fouille données ➢ université paris licence mathématique informatique ➢ lycée paul éluard préparatoire concours polytechnique physique mathématique ➢ lycée suger – bac lauréat scientifique – spécialité mathématique mention bien points forts compétences diplômes mailtolukakutresorgmailcom ➢ aws solution architecture cours ➢ azure az cours agircarrco octobre cours architecte hadoop cloudera contexte mission sein lorganisation direction technique informatique structure appelée gouvernance opérationnelle l’edition goe mission daccompagner développement logiciel réalisé entités fonctionnelles s’appuie entités socle développement architecture logicielle centre d’expertise performances dbassocles principales missions consistent dune accompagner équipes conception modèles données administrer bases moteurs bases données construire socles sgbd décisionnel bigdata actions menées ➢ architecture technique • mise place principes directeur l’utilisation cluster cloudera • vérification bonne application normes standards • proposition d’évolution solution améliorer l’industrialisation ➢ administration • configuration cluster cloudera fonction besoins identifiés • suivi espaces stockage • optimisation chargement données • maintien sécurité ➢ intégration • nouveau besoin etude proposition solution mise œuvre solution validés ➢ support technique • maintien condition opérationnelle infrastructures composants logiciels cluster • assistance auprès équipes optimisation traitement prise main l’outillage • chargement données • transmission savoir faire rédaction documentation transfert connaissance ➢ support décisionnel • assistance auprès équipes si décisionnel l’évolution plateforme • recolte analyse besoins • description analyse plateforme actuelle • proposition dévolution élaboration dossier d’architecture technique logicielle environnement technique utilisé hadoop cloudera shell spark hue hive python scala ansible certifications missions effectuees bouygues telecom février octobre ingenieur big data contexte mission daméliorer compréhension données datalake datawarehouse ainsi faire croître culture data sein lentreprise faire étude indicateurs suivi kpi complétudes données jai sollicité bouygues telecom afin dapporter mon expertise sujet actions menées ➢ frise chronologique projet ➢ démarche modélisation ➢ documentations données ➢ méthodologie dictionnarisassions données ➢ etudes cas dusages indicateur suivi kpi complétude donnée environnement technique utilisé datagalaxydatacatalog scala sbt java spark ministere tourisme novembre – janvier data ingenieur scientist contexte mission atout france agence développement touristique france groupement dintérêt économique gie létat français matière tourisme missions ont définies cadre loi tourisme renforcer positionnements destination france linternational projet était contribuer activement marketing international destinations filières daccompagner territoires leur stratégie développement favorisant montage projets dinvestissement afin stimuler loffre touristique française agissant qualité pilotage classements hébergements touristiques marchands proposant toute offre services matière veilleobservation formation atout france met ainsi disposition partenaires publics privé outils compréhension demande touristique leur propose actions marketing promotion autour marque mondiales destination afin renforcer leur développement linternational actions menées ➢ agreger données sources multiples ➢ structurer indicateurs utiles décision politique institutionnels professionnels ➢ proposer faciliter analyses partagées permettre usages périmètre pluriel national régional départementale ➢ automatisations pipelines ➢ création automatisation mis jour dataframe hubskeyrops ➢ test unitaire ➢ test integration environnement technique utilisé python spark scalasbt powerbi minio agil jira missions effectuees sanofi septembre octobre data scientist contexte mission lun plus grand groupe pharmaceutique mondial ma mission était orientée détection anomalies maintenances prédictives indicateurs performance kpis traitements langage naturel opérations qualité́ lindustrie manufacturière audelà̀ actions menées ➢ mise place algorithmes classification régression ➢ mise place algorithmes dapprentissage adaptatif modèle basé liaml apprend permanence ➢ participer définition nouvelles fonctionnalités loutil ➢ collaborer création plateforme ➢ pendre définition variations récurrentes ➢ contribuer lextension modèle sera mis disposition utiliser production environnement technique utilisé python aws r agile scrum avisto mars septembre data scientist contexte mission avisto entreprise créations logiciels informatiques cadre activité́ils lancés secteurs jeux réalité́virtuelle ligne pokeria mission était mettre place algorithme deep learningrnn afin réaliser jeu poker ligne rivaliser autres poker existant google facebook actions menées ➢ études approfondies différents pokers ligne existant etat l’art ➢ écriture cahier charges ➢ conceptions scenarios partie graphique jeux ➢ mise place différentes architectures machine learning deeplearning ➢ mlops equipe po data science développeur angular environnement technique utilisé python r aws spark angular agil scrum sncf février février data ingenieur scientist contexte mission sncf voudriez cartographier compétences collaborateurs fonctions expériences environnement techniques répondre besoins lentreprises différents projets également cibler compétences manquantes lentreprise termes recrutement actions menées ➢ analyse développement applications gestion automatique appels doffres ➢ apprentissage larchitecture machine learning conceptions applications mobiles site web ➢ automatisations pipelines ➢ test unitaire ➢ test integration equipe po data science data engineer environnement technique utilisé python r java scala sbt hadoop agile powerbi dataiku aws laboratoire recherche paris janvier mai data ingenieur contexte mission cadre missions recherche développement rd j’ai participé différents travaux lexploitation donnée déploiements lintelligence artificielle divers domaines actions menées ➢ analyse sentiment contenu tweet autour dun motcle ➢ analyse réservations vélo «velib» ➢ analyse réservations vélo «velib» environnement technique utilisé scala spark hadoop cloudera hive mongodb mysql r knime kafka powerbi dataiku aws concours challenges synthèses images sons ➢ juin juin langage java python concours national api ➢ juin langage java c concours national api ➢ juin langage java python concours national api,